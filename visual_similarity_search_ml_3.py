# -*- coding: utf-8 -*-
"""visual-similarity-search ML 3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oVvGg0J0g62PezRtrkr594N7iMQyHrXb

Visual similarity search using image embedding involves several steps. First, a pretrained neural network, such as a convolutional neural network (CNN), is used to extract visual features from images, which are represented as vector embeddings in a lower-dimensional space that preserves relative dissimilarity. These vector embeddings are then stored in a database for efficient retrieval.

When a user inputs an image for similarity search, the same pretrained network is used to extract visual features from the input image and obtain its vector embedding in the same embedding space as the stored embeddings. The distance between the vector embedding of the input image and all the vector embeddings in the database is calculated using distance metrics such as Euclidean distance or cosine distance, which measure the similarity or dissimilarity between the embeddings.

Based on the calculated distances, the k-Nearest Neighbours (k-NN) algorithm is used to find the k most similar image embeddings in the database. These k nearest neighbours represent the most visually similar products or images to the input image, and the results can be displayed to the user. To evaluate the success of the similarity search algorithm, subjective metrics such as hit-rate and A/B tests can be used to measure the accuracy of the recommendations.

In summary, visual similarity search using image embedding involves extracting visual features, representing them as vector embeddings, and comparing the embeddings to find visually similar products or images in a database. Evaluation of the algorithm can be done using subjective metrics and testing to ensure accurate recommendations.
"""

! pip install kaggle

from google.colab import files
files.upload()

#create a JSON Folder
! mkdir ~/.kaggle

#Copy Kaggle.json to folder created

! cp kaggle.json ~/.kaggle/

#Permission For Json to act
! chmod 600 ~/.kaggle/kaggle.json

! kaggle datasets list

! kaggle datasets download -d paramaggarwal/fashion-product-images-dataset

! unzip fashion-product-images-dataset

import numpy as np
import pandas as pd
import os
import re
import tensorflow as tf
from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Activation, Dropout, Flatten, Dense, Input, Layer
from tensorflow.keras.applications import VGG16
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array
import matplotlib.pyplot as plt
import seaborn as sns

plt.rcParams['font.size'] = 16

img_path = '/content/fashion-dataset/fashion-dataset/images'
img_df = pd.read_csv('/content/fashion-dataset/fashion-dataset/images.csv')
styles_df = pd.read_csv('/content/fashion-dataset/fashion-dataset/styles.csv', on_bad_lines='skip')

img_df.head()

styles_df.head()

styles_df['filename'] = styles_df['id'].astype(str) + '.jpg'

styles_df

img_files = os.listdir(img_path)

styles_df['present'] = styles_df['filename'].apply(lambda x:x in img_files)

styles_df = styles_df[styles_df['present']].reset_index(drop=True)

styles_df = styles_df.sample(10000)

img_size = 224

datagen = ImageDataGenerator(rescale=1/255.)

generator = datagen.flow_from_dataframe(dataframe = styles_df,
                                       directory = img_path,
                                       target_size = (img_size,img_size),
                                       x_col = 'filename',
                                       class_mode = None,
                                       batch_size = 32,
                                       shuffle = False,
                                       classes= None)

base_model = VGG16(include_top=False, input_shape= (img_size,img_size,3))

for layer in base_model.layers:
    layer.trainable = False


input_layer = Input(shape=(img_size,img_size,3))
x= base_model(input_layer)
output= GlobalAveragePooling2D()(x)

embeddings = Model(inputs = input_layer, outputs= output)
embeddings.summary()

X = embeddings.predict(generator, verbose=1)

"""# PCA"""

from sklearn.decomposition import PCA

pca = PCA(2)
X_pca = pca.fit_transform(X)

styles_df[['pc1', 'pc2']] = X_pca

plt.figure(figsize= (20,12))
sns.scatterplot(x='pc1',y='pc2',data = styles_df)
plt.show()

def read_img(image_path):
    image = load_img(os.path.join(img_path,image_path),target_size=(img_size,img_size,3))
    image = img_to_array(image)
    image = image/255.
    return image

import random
from sklearn.neighbors import KNeighborsClassifier

y = styles_df['id']

nearest_neighbors = KNeighborsClassifier(n_neighbors = 7)
nearest_neighbors.fit(X,y)

styles_df = styles_df.reset_index(drop=True)

for _ in range(10):
    i = random.randint(0,len(styles_df))
    img1 = read_img(styles_df.loc[i,'filename'])
    dist, index = nearest_neighbors.kneighbors(X=X[i,:].reshape(1,-1))
    plt.figure(figsize = (4 , 4))
    plt.imshow(img1)
    plt.title("Input Image")
    plt.axis('off')

    plt.figure(figsize = (20 , 20))
    for i in range(1,6):
        plt.subplot(1 , 5, i)
        plt.subplots_adjust(hspace = 0.5 , wspace = 0.3)
        image = read_img(styles_df.loc[index[0][i],'filename'])
        plt.imshow(image)
        plt.title(f'Similar Product #{i}')
        plt.axis('off')

